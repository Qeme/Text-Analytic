{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4ce7a1",
   "metadata": {},
   "source": [
    "# P1: Wan Muhammad Luqman Bin Wan Azinuddin (SW01081339)\n",
    "# P2: Muhammad Aflahul Wafi bin Amalik (SW01081772)\n",
    "# Section 01B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82883fbd-7c2b-4b4d-8178-0f0904797f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amirul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amirul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amirul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9e2d63-d35f-4092-a236-8a395345095c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "      <td>\\nYo! Watch the attributions--I didn't say tha...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73</td>\n",
       "      <td>\\nYou can avoid these problems entirely by ins...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77</td>\n",
       "      <td>I have a 1986 Acura Integra 5 speed with 95,00...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84</td>\n",
       "      <td>\\nassuming yours is a non turbo MR2, the gruff...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156</td>\n",
       "      <td>\\n\\nIn addition to restricted mileage, many cl...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201</td>\n",
       "      <td>\\n\\nSeveral years ago GM was having trouble wi...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>207</td>\n",
       "      <td>\\nI had the same problem in my '90 MX-6. Lucki...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>216</td>\n",
       "      <td>As an additional data point, I have run Castro...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>262</td>\n",
       "      <td>\\nWomen's pants rarely have pockets and most, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>274</td>\n",
       "      <td>\\n\\nI agree.  Six hour long stretches behind t...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>405</td>\n",
       "      <td>From: thwang@mentor.cc.purdue.edu (Tommy Hwang...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>415</td>\n",
       "      <td>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>445</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nBzzt.\\nThe manta was a two-door se...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>462</td>\n",
       "      <td>sorry about that last post, my server neglecte...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>463</td>\n",
       "      <td>From article &lt;1993Apr5.200048.23421@ucsu.Color...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  target  \\\n",
       "0            0  I was wondering if anyone out there could enli...       7   \n",
       "1           17  I recently posted an article asking what kind ...       7   \n",
       "2           29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "3           56  an excellent automatic can be found in the sub...       7   \n",
       "4           64  : Ford and his automobile.  I need information...       7   \n",
       "5           71  \\nYo! Watch the attributions--I didn't say tha...       7   \n",
       "6           73  \\nYou can avoid these problems entirely by ins...       7   \n",
       "7           77  I have a 1986 Acura Integra 5 speed with 95,00...       7   \n",
       "8           84  \\nassuming yours is a non turbo MR2, the gruff...       7   \n",
       "9          156  \\n\\nIn addition to restricted mileage, many cl...       7   \n",
       "10         201  \\n\\nSeveral years ago GM was having trouble wi...       7   \n",
       "11         207  \\nI had the same problem in my '90 MX-6. Lucki...       7   \n",
       "12         216  As an additional data point, I have run Castro...       7   \n",
       "13         262  \\nWomen's pants rarely have pockets and most, ...       7   \n",
       "14         274  \\n\\nI agree.  Six hour long stretches behind t...       7   \n",
       "15         405  From: thwang@mentor.cc.purdue.edu (Tommy Hwang...       7   \n",
       "16         415              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^...       7   \n",
       "17         445  \\n\\n\\n\\n\\n\\nBzzt.\\nThe manta was a two-door se...       7   \n",
       "18         462  sorry about that last post, my server neglecte...       7   \n",
       "19         463  From article <1993Apr5.200048.23421@ucsu.Color...       7   \n",
       "\n",
       "        title                        date  \n",
       "0   rec.autos  2022-08-02 13:48:37.251043  \n",
       "1   rec.autos  2022-08-02 13:48:37.251043  \n",
       "2   rec.autos  2022-08-02 13:48:37.251043  \n",
       "3   rec.autos  2022-08-02 13:48:37.251043  \n",
       "4   rec.autos  2022-08-02 13:48:37.251043  \n",
       "5   rec.autos  2022-08-02 13:48:37.251043  \n",
       "6   rec.autos  2022-08-02 13:48:37.251043  \n",
       "7   rec.autos  2022-08-02 13:48:37.251043  \n",
       "8   rec.autos  2022-08-02 13:48:37.251043  \n",
       "9   rec.autos  2022-08-02 13:48:37.251043  \n",
       "10  rec.autos  2022-08-02 13:48:37.251043  \n",
       "11  rec.autos  2022-08-02 13:48:37.251043  \n",
       "12  rec.autos  2022-08-02 13:48:37.251043  \n",
       "13  rec.autos  2022-08-02 13:48:37.251043  \n",
       "14  rec.autos  2022-08-02 13:48:37.251043  \n",
       "15  rec.autos  2022-08-02 13:48:37.251043  \n",
       "16  rec.autos  2022-08-02 13:48:37.251043  \n",
       "17  rec.autos  2022-08-02 13:48:37.251043  \n",
       "18  rec.autos  2022-08-02 13:48:37.251043  \n",
       "19  rec.autos  2022-08-02 13:48:37.251043  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"news_dataset.csv\")\n",
    "data = data.dropna(subset=['text'])\n",
    "data = data.drop_duplicates()\n",
    "data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d1be5d-c349-40ee-906b-3cb8f8176030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11096, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c770cc10-0521-445d-9729-6dce6dc8c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I was wondering if anyone out there could enli...\n",
       "1    I recently posted an article asking what kind ...\n",
       "2    \\nIt depends on your priorities.  A lot of peo...\n",
       "3    an excellent automatic can be found in the sub...\n",
       "4    : Ford and his automobile.  I need information...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select Text column\n",
    "datatext = data['text']\n",
    "datatext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f13f53-0c95-4150-96ce-ab0320fcd33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "datatext_dup = datatext.duplicated()\n",
    "print(datatext_dup.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bd194b-ab54-4e5f-9a06-9cd1fb4ba831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amirul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amirul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\amirul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[wondering, anyone, could, enlighten, car, saw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[recently, posted, article, asking, kind, rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[depends, priority, lot, people, put, higher, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[excellent, automatic, found, subaru, legacy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[ford, automobile, need, information, whether,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "      <td>\\nYo! Watch the attributions--I didn't say tha...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[yo, watch, attributionsi, didnt, say, isnt, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73</td>\n",
       "      <td>\\nYou can avoid these problems entirely by ins...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[avoid, problem, entirely, installing, oil, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77</td>\n",
       "      <td>I have a 1986 Acura Integra 5 speed with 95,00...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[acura, integra, speed, mile, positively, wors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84</td>\n",
       "      <td>\\nassuming yours is a non turbo MR2, the gruff...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[assuming, non, turbo, gruffness, characterist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156</td>\n",
       "      <td>\\n\\nIn addition to restricted mileage, many cl...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[addition, restricted, mileage, many, classic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201</td>\n",
       "      <td>\\n\\nSeveral years ago GM was having trouble wi...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[several, year, ago, gm, trouble, ring, sticki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>207</td>\n",
       "      <td>\\nI had the same problem in my '90 MX-6. Lucki...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[problem, luckily, fixed, warranty, think, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>216</td>\n",
       "      <td>As an additional data point, I have run Castro...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[additional, data, point, run, castrol, exclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>262</td>\n",
       "      <td>\\nWomen's pants rarely have pockets and most, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[woman, pant, rarely, pocket, shallow, use, im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>274</td>\n",
       "      <td>\\n\\nI agree.  Six hour long stretches behind t...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[agree, six, hour, long, stretch, behind, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>405</td>\n",
       "      <td>From: thwang@mentor.cc.purdue.edu (Tommy Hwang...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[thwangmentorccpurdueedu, tommy, hwang, subjec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>415</td>\n",
       "      <td>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[know, isnt, group, since, brought, anyone, id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>445</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nBzzt.\\nThe manta was a two-door se...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[bzzt, manta, twodoor, sedan, u, engine, somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>462</td>\n",
       "      <td>sorry about that last post, my server neglecte...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[sorry, last, post, server, neglected, send, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>463</td>\n",
       "      <td>From article &lt;1993Apr5.200048.23421@ucsu.Color...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "      <td>[article, lorenzorintintincoloradoedu, eric, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  target  \\\n",
       "0            0  I was wondering if anyone out there could enli...       7   \n",
       "1           17  I recently posted an article asking what kind ...       7   \n",
       "2           29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "3           56  an excellent automatic can be found in the sub...       7   \n",
       "4           64  : Ford and his automobile.  I need information...       7   \n",
       "5           71  \\nYo! Watch the attributions--I didn't say tha...       7   \n",
       "6           73  \\nYou can avoid these problems entirely by ins...       7   \n",
       "7           77  I have a 1986 Acura Integra 5 speed with 95,00...       7   \n",
       "8           84  \\nassuming yours is a non turbo MR2, the gruff...       7   \n",
       "9          156  \\n\\nIn addition to restricted mileage, many cl...       7   \n",
       "10         201  \\n\\nSeveral years ago GM was having trouble wi...       7   \n",
       "11         207  \\nI had the same problem in my '90 MX-6. Lucki...       7   \n",
       "12         216  As an additional data point, I have run Castro...       7   \n",
       "13         262  \\nWomen's pants rarely have pockets and most, ...       7   \n",
       "14         274  \\n\\nI agree.  Six hour long stretches behind t...       7   \n",
       "15         405  From: thwang@mentor.cc.purdue.edu (Tommy Hwang...       7   \n",
       "16         415              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^...       7   \n",
       "17         445  \\n\\n\\n\\n\\n\\nBzzt.\\nThe manta was a two-door se...       7   \n",
       "18         462  sorry about that last post, my server neglecte...       7   \n",
       "19         463  From article <1993Apr5.200048.23421@ucsu.Color...       7   \n",
       "\n",
       "        title                        date  \\\n",
       "0   rec.autos  2022-08-02 13:48:37.251043   \n",
       "1   rec.autos  2022-08-02 13:48:37.251043   \n",
       "2   rec.autos  2022-08-02 13:48:37.251043   \n",
       "3   rec.autos  2022-08-02 13:48:37.251043   \n",
       "4   rec.autos  2022-08-02 13:48:37.251043   \n",
       "5   rec.autos  2022-08-02 13:48:37.251043   \n",
       "6   rec.autos  2022-08-02 13:48:37.251043   \n",
       "7   rec.autos  2022-08-02 13:48:37.251043   \n",
       "8   rec.autos  2022-08-02 13:48:37.251043   \n",
       "9   rec.autos  2022-08-02 13:48:37.251043   \n",
       "10  rec.autos  2022-08-02 13:48:37.251043   \n",
       "11  rec.autos  2022-08-02 13:48:37.251043   \n",
       "12  rec.autos  2022-08-02 13:48:37.251043   \n",
       "13  rec.autos  2022-08-02 13:48:37.251043   \n",
       "14  rec.autos  2022-08-02 13:48:37.251043   \n",
       "15  rec.autos  2022-08-02 13:48:37.251043   \n",
       "16  rec.autos  2022-08-02 13:48:37.251043   \n",
       "17  rec.autos  2022-08-02 13:48:37.251043   \n",
       "18  rec.autos  2022-08-02 13:48:37.251043   \n",
       "19  rec.autos  2022-08-02 13:48:37.251043   \n",
       "\n",
       "                                        message_clean  \n",
       "0   [wondering, anyone, could, enlighten, car, saw...  \n",
       "1   [recently, posted, article, asking, kind, rate...  \n",
       "2   [depends, priority, lot, people, put, higher, ...  \n",
       "3   [excellent, automatic, found, subaru, legacy, ...  \n",
       "4   [ford, automobile, need, information, whether,...  \n",
       "5   [yo, watch, attributionsi, didnt, say, isnt, a...  \n",
       "6   [avoid, problem, entirely, installing, oil, dr...  \n",
       "7   [acura, integra, speed, mile, positively, wors...  \n",
       "8   [assuming, non, turbo, gruffness, characterist...  \n",
       "9   [addition, restricted, mileage, many, classic,...  \n",
       "10  [several, year, ago, gm, trouble, ring, sticki...  \n",
       "11  [problem, luckily, fixed, warranty, think, rep...  \n",
       "12  [additional, data, point, run, castrol, exclus...  \n",
       "13  [woman, pant, rarely, pocket, shallow, use, im...  \n",
       "14  [agree, six, hour, long, stretch, behind, whee...  \n",
       "15  [thwangmentorccpurdueedu, tommy, hwang, subjec...  \n",
       "16  [know, isnt, group, since, brought, anyone, id...  \n",
       "17  [bzzt, manta, twodoor, sedan, u, engine, somet...  \n",
       "18  [sorry, last, post, server, neglected, send, m...  \n",
       "19  [article, lorenzorintintincoloradoedu, eric, l...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "\n",
    "# Download the stopwords dataset\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "# Define stop words\n",
    "stop_words = stopwords.words('english')\n",
    "more_stopwords = ['u', 'im', 'c', 'maxaxaxaxaxaxaxaxaxaxaxaxaxaxax']\n",
    "stop_words.extend(more_stopwords)\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\b\\w*\\d\\w*\\b', '', text)  # Remove words containing numbers\n",
    "    text = re.sub(r'\\S+@\\S+', '', text) \n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "data['message_clean'] = data['text'].apply(preprocess)\n",
    "\n",
    "data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474d9736-b0e3-4866-a72f-e83ead16e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform LDA using Gensim library\n",
    "\n",
    "#import topic modelling as well\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c670ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Gensim Dictionary object from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(data['message_clean'])\n",
    "#convert each preprocessed document into a bag-of-words representation using the dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in data['message_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331c7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e872a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now see the result\n",
    "\n",
    "#create an empty array to store dominant topic labels for each document\n",
    "article_labels = []\n",
    "\n",
    "#iterate over each processed document\n",
    "for i, doc in enumerate(data['message_clean']):\n",
    "    #for each document,convert to box representation\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    #get list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    #determine topic with highest probability\n",
    "    dominant_topic = max(topics, key=lambda x:x[1])[0]\n",
    "    #appendf to the list\n",
    "    article_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e39a3da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                    Text  Topic\n",
      "0      I was wondering if anyone out there could enli...      3\n",
      "1      I recently posted an article asking what kind ...      3\n",
      "2      \\nIt depends on your priorities.  A lot of peo...      3\n",
      "3      an excellent automatic can be found in the sub...      3\n",
      "4      : Ford and his automobile.  I need information...      3\n",
      "...                                                  ...    ...\n",
      "11309  Secrecy in Clipper Chip\\n\\nThe serial number o...      2\n",
      "11310  Hi !\\n\\nI am interested in the source of FEAL ...      2\n",
      "11311  The actual algorithm is classified, however, t...      1\n",
      "11312  \\n\\tThis appears to be generic calling upon th...      3\n",
      "11313  \\nProbably keep quiet and take it, lest they g...      3\n",
      "\n",
      "[11096 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#create dataframe to see them\n",
    "df = pd.DataFrame({\"Text\": data['text'], \"Topic\": article_labels})\n",
    "\n",
    "#Now print them to see the result\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f10be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"game\" (weight: 0.011)\n",
      "- \"team\" (weight: 0.010)\n",
      "- \"player\" (weight: 0.006)\n",
      "- \"season\" (weight: 0.005)\n",
      "- \"play\" (weight: 0.005)\n",
      "- \"league\" (weight: 0.004)\n",
      "- \"space\" (weight: 0.004)\n",
      "- \"new\" (weight: 0.004)\n",
      "- \"year\" (weight: 0.004)\n",
      "- \"hockey\" (weight: 0.004)\n",
      "\n",
      "Topic 1:\n",
      "- \"government\" (weight: 0.008)\n",
      "- \"q\" (weight: 0.006)\n",
      "- \"people\" (weight: 0.006)\n",
      "- \"state\" (weight: 0.005)\n",
      "- \"president\" (weight: 0.005)\n",
      "- \"law\" (weight: 0.004)\n",
      "- \"u\" (weight: 0.004)\n",
      "- \"mr\" (weight: 0.004)\n",
      "- \"encryption\" (weight: 0.004)\n",
      "- \"right\" (weight: 0.004)\n",
      "\n",
      "Topic 2:\n",
      "- \"x\" (weight: 0.016)\n",
      "- \"key\" (weight: 0.008)\n",
      "- \"file\" (weight: 0.007)\n",
      "- \"use\" (weight: 0.007)\n",
      "- \"system\" (weight: 0.006)\n",
      "- \"db\" (weight: 0.005)\n",
      "- \"one\" (weight: 0.005)\n",
      "- \"window\" (weight: 0.005)\n",
      "- \"chip\" (weight: 0.004)\n",
      "- \"get\" (weight: 0.004)\n",
      "\n",
      "Topic 3:\n",
      "- \"one\" (weight: 0.010)\n",
      "- \"would\" (weight: 0.010)\n",
      "- \"dont\" (weight: 0.008)\n",
      "- \"think\" (weight: 0.007)\n",
      "- \"people\" (weight: 0.007)\n",
      "- \"know\" (weight: 0.006)\n",
      "- \"like\" (weight: 0.006)\n",
      "- \"say\" (weight: 0.005)\n",
      "- \"get\" (weight: 0.005)\n",
      "- \"time\" (weight: 0.005)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prnt the top terms for each topic\n",
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519c784-dc85-4f1f-8af3-f775f1df5a64",
   "metadata": {},
   "source": [
    "Topic 0 are related to sports or games where the weight of terms like \"game\" and \"team\" are particularly high, indicating their significance in this topic.\n",
    "\n",
    "Topic 1 are talking about the internal of country politics where the weight of terms like \"government\" and \"people\" are particularly high, indicating their significance in this topic.\n",
    "\n",
    "Topic 2 are related to computer system where the weight of terms like \"x\" , \"key\" and \"file\" are particularly high, indicating their significance in this topic.\n",
    "\n",
    "Topic 3 are discussions where individuals express their views on various subjects since all the topic are very common word such as \"one\", \"would\" and \"don't\" are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9695b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for Topic #0:\n",
      "['game', 'team', 'player', 'season', 'play', 'league', 'space', 'new', 'year', 'hockey']\n",
      "\n",
      "Top terms for Topic #1:\n",
      "['government', 'q', 'people', 'state', 'president', 'law', 'u', 'mr', 'encryption', 'right']\n",
      "\n",
      "Top terms for Topic #2:\n",
      "['x', 'key', 'file', 'use', 'system', 'db', 'one', 'window', 'chip', 'get']\n",
      "\n",
      "Top terms for Topic #3:\n",
      "['one', 'would', 'dont', 'think', 'people', 'know', 'like', 'say', 'get', 'time']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms for each topic\n",
    "for topic_id in range(lda_model.num_topics):\n",
    "    print(f\"Top terms for Topic #{topic_id}:\")\n",
    "    top_terms = lda_model.show_topic(topic_id, topn=10)\n",
    "    print([term[0] for term in top_terms])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca9ccb-d152-458a-a6ae-f1ab46066137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
